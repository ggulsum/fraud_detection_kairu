# Fraud Detection Pipeline

## ğŸ“Œ Genel BakÄ±ÅŸ

[pipeline.py](src/pipeline.py), **dolandÄ±rÄ±cÄ±lÄ±k (fraud)** tespiti iÃ§in tasarlanmÄ±ÅŸ uÃ§tan uca (**end-to-end**) bir veri iÅŸleme ve modelleme akÄ±ÅŸÄ±nÄ± (**pipeline**) yÃ¶netir.
Bu dosya tek baÅŸÄ±na Ã§alÄ±ÅŸtÄ±rÄ±labilir bir Python modÃ¼lÃ¼dÃ¼r ve aÅŸaÄŸÄ±daki adÄ±mlarÄ± gerÃ§ekleÅŸtirir:

* Veri yÃ¼kleme ve doÄŸrulama
* Ã–n iÅŸleme (scaling, encoding, feature engineering)
* Veri dengesizliÄŸi giderme (SMOTE, ADASYN, vb.)
* Model eÄŸitimi (Random Forest, Logistic Regression, Isolation Forest, LOF)
* Model deÄŸerlendirme (ROC-AUC, F1, Precision, Recall, PR-AUC)
* Model kaydetme ve yÃ¼kleme
* Tahmin ve aÃ§Ä±klanabilirlik (Explainability)
* Tam pipeline Ã§alÄ±ÅŸtÄ±rma (end-to-end)

Kod, modÃ¼ler bir yapÄ±ya sahiptir ve aÅŸaÄŸÄ±daki dÄ±ÅŸ modÃ¼lleri kullanÄ±r:

* `FeaturePreprocessor`
* `ImbalanceHandler`
* `FraudEvaluator`
* `OutlierDetector`
* `ModelExplainer`

---

## Class: `FraudDetectionPipeline`

### 1ï¸âƒ£ Constructor

```python
def __init__(self, config_path="config/config.yaml"):
```

**AmaÃ§:** Pipeline konfigÃ¼rasyonunu yÃ¼kler, loglama ve MLflow ayarlarÄ±nÄ± yapar.

**Parametre:**

* `config_path` â€” YAML formatÄ±nda pipeline ayar dosyasÄ±nÄ±n yolu.

**YapÄ±lan Ä°ÅŸlemler:**

* Config dosyasÄ± okunur.
* Logging sistemi baÅŸlatÄ±lÄ±r.
* MLflow baÄŸlantÄ±sÄ± kurulur (deney kaydÄ± iÃ§in).

---

### 2ï¸âƒ£ `load_data()`

```python
def load_data(self, data_path=None, synthetic=True, download_with_kagglehub=False):
```

**AmaÃ§:** EÄŸitim iÃ§in veri yÃ¼klemek.

**Parametreler:**

* `data_path`: Dosya yolu (CSV)
* `synthetic`: `True` ise sentetik veri oluÅŸturur
* `download_with_kagglehub`: `True` ise KaggleHub Ã¼zerinden veri indirir

**DÃ¶nÃ¼ÅŸ:**
`self.data` â†’ *pandas DataFrame*

Ek: `_validate_data()` ile ÅŸema ve eksik deÄŸer kontrolÃ¼ yapÄ±lÄ±r.

**KaggleHub kullanÄ±mÄ±:**

```bash
python src/pipeline.py --mode train --use_kagglehub
```
---

### 3ï¸âƒ£ `_generate_synthetic_data()`

**AmaÃ§:** GerÃ§ek veri yoksa test amaÃ§lÄ± rastgele sahte veri Ã¼retir.
**DÃ¶nÃ¼ÅŸ:** `DataFrame` (amount, time, class, vb. sÃ¼tunlar iÃ§erir)

---

### 4ï¸âƒ£ `_validate_data()`

**AmaÃ§:** Veri kalitesini ve bÃ¼tÃ¼nlÃ¼ÄŸÃ¼nÃ¼ kontrol eder.

**Kontroller:**

* Eksik deÄŸer yÃ¼zdesi (`missing_threshold`)
* Gerekli sÃ¼tunlarÄ±n varlÄ±ÄŸÄ±
* SayÄ±sal deÄŸer aralÄ±klarÄ± (Ã¶r. `amount > 0`)
* `class` deÄŸerlerinin uygunluÄŸu (`0/1`)

HatalÄ± durumda: `ValueError` fÄ±rlatÄ±r ve iÅŸlem durur.

---

### 5ï¸âƒ£ `preprocess_data()`

**AmaÃ§:** Veri Ã¼zerinde Ã¶n iÅŸleme yapmak.

**Ä°Ã§erik:**

* Kategorik/sayÄ±sal sÃ¼tun ayrÄ±mÄ±
* Ã–lÃ§ekleme (`robust`, `standard`, `minmax`)
* Encoding (`onehot`, `label`)
* Eksik veri doldurma (imputation)
* Veri dengesizliÄŸi giderme (SMOTE, ADASYN, vb.)

**KullanÄ±r:**

* `FeaturePreprocessor`
* `ImbalanceHandler`

**DÃ¶nÃ¼ÅŸ:**
`self.X_train`, `self.X_test`, `self.y_train`, `self.y_test`

---

### 6ï¸âƒ£ `train_models()`

**AmaÃ§:** Configâ€™de tanÄ±mlÄ± tÃ¼m modelleri eÄŸitir.

**Desteklenen modeller:**

* `RandomForestClassifier`
* `LogisticRegression`
* `IsolationForest`
* `LocalOutlierFactor`

**DÃ¶nÃ¼ÅŸ:**
`self.models` â†’ `{ model_adÄ±: model_nesnesi }`

MLflow aktifse, her model iÃ§in ayrÄ± bir â€œrunâ€ olarak kaydeder.

---

### 7ï¸âƒ£ `evaluate_models()`

**AmaÃ§:** Her modeli test verisinde deÄŸerlendirir.

**KullanÄ±r:** 
* `FraudEvaluator`
* `OutlierDetector` (Ã¶zellikle Isolation Forest ve LOF iÃ§in)

**Metrikler:**

* ROC-AUC
* PR-AUC
* F1-score
* Precision, Recall

**DÃ¶nÃ¼ÅŸ:**
`{ model_adÄ±: metrik_sonuÃ§larÄ± }`

En iyi modeli `_find_best_model()` fonksiyonu seÃ§er.

---

### 8ï¸âƒ£ `save_models()` / `load_models()`

**AmaÃ§:** EÄŸitilen modelleri ve Ã¶n iÅŸleme nesnelerini kaydetmek veya yeniden yÃ¼klemek.

**KayÄ±t edilen dosyalar:**

* `preprocessor.pkl`
* `<model_adÄ±>_model.pkl`
* `feature_info.pkl`

**KullanÄ±lan araÃ§:** `joblib`

---

### 9ï¸âƒ£ `predict()`

```python
def predict(self, data, model_name="random_forest"):
```

**AmaÃ§:** Yeni veriler Ã¼zerinde tahmin yapmak.

**Parametreler:**

* `data`: DataFrame formatÄ±nda yeni veri
* `model_name`: KullanÄ±lacak modelin adÄ±

**DÃ¶nÃ¼ÅŸ:**
`predictions` â†’ `numpy array` veya `DataFrame`

---

### ğŸ”Ÿ `explain_models()`

**AmaÃ§:** Modelin kararlarÄ±nÄ± aÃ§Ä±klamak (SHAP / LIME tabanlÄ±).

Not: `explainability_clean.py` modÃ¼lÃ¼ mevcutsa `ModelExplainer` Ã§aÄŸrÄ±lÄ±r, yoksa uyarÄ± verip atlanÄ±r.

**Girdi:** Model adÄ±
**DÃ¶nÃ¼ÅŸ:** Grafik veya aÃ§Ä±klama Ã§Ä±ktÄ±sÄ± 

---

### 1ï¸âƒ£1ï¸âƒ£ `run_full_pipeline()`

**AmaÃ§:** Tek komutla tÃ¼m sÃ¼reci baÅŸtan sona Ã§alÄ±ÅŸtÄ±rmak:

1. Veri yÃ¼kle
2. Ã–n iÅŸle
3. Modelleri eÄŸit
4. DeÄŸerlendir
5. En iyi modeli kaydet

**DÃ¶nÃ¼ÅŸ:** En iyi modelin adÄ± ve metrikleri.
Fonksiyon, tÃ¼m adÄ±mlar baÅŸarÄ±yla tamamlandÄ±ÄŸÄ±nda True, hata durumunda False dÃ¶ndÃ¼rÃ¼r.

---

## CLI (Komut SatÄ±rÄ±) KullanÄ±mÄ±

Pipeline, doÄŸrudan komut satÄ±rÄ±ndan Ã§alÄ±ÅŸtÄ±rÄ±labilir:

```bash
python src/pipeline.py
```

---

## Ã–zet

Bu dosya:

* Fraud tespiti iÃ§in tamamen otomatik bir modelleme akÄ±ÅŸÄ± sunar.
* Her adÄ±mÄ± modÃ¼ler, aÃ§Ä±klanabilir ve yeniden kullanÄ±labilir olacak ÅŸekilde tasarlanmÄ±ÅŸtÄ±r.
* CLIâ€™dan veya kod iÃ§inden kolayca Ã§alÄ±ÅŸtÄ±rÄ±labilir.
* MLflow ile deney takibi yapÄ±labilir.
* SHAP tabanlÄ± aÃ§Ä±klamalarla model davranÄ±ÅŸÄ± analiz edilebilir.

---

